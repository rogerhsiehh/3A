{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install gym\n",
    "# !pip install keras\n",
    "# !pip install keras-rl2\n",
    "# !pip install stable-baselines3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create environment follows Gym that SB3 supports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.youtube.com/watch?v=cO5g5qLrLSo&ab_channel=NicholasRenotte\n",
    "* https://www.youtube.com/watch?v=bD6V3rcr_54&list=PLgNJO2hghbmjlE6cuKMws2ejC54BTAaWV&index=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "class TaxiChargingEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(TaxiChargingEnv, self).__init__()\n",
    "        # Actions we take: 0 kW, 7 kW, 14 kW, 22 kW\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        # State represents battery charge level (kWh)\n",
    "        self.observation_space = spaces.Box(low=np.array([0]), high=np.array([100]), dtype=np.float32)\n",
    "        # Initialize state\n",
    "        self.state = 0.0\n",
    "        # Battery capacity\n",
    "        self.battery_capacity = 100.0  # kWh\n",
    "        # Initial battery level\n",
    "        self.battery_level = float(random.randint(20, 30))\n",
    "        # Charging period (2 hours, every 15 minutes = 8 steps)\n",
    "        self.steps_left = 8\n",
    "        # Energy demand parameters\n",
    "        self.mu = 30.0  # kWh\n",
    "        self.sigma = 5.0  # kWh\n",
    "        # Time coefficient for cost function\n",
    "        self.alpha = 1\n",
    "\n",
    "    def step(self, action):\n",
    "        charging_rates = [0, 7, 14, 22]  # kW for each action\n",
    "        power = charging_rates[action]\n",
    "\n",
    "        # Calculate cost: charging cost (t,p) = 𝛼𝑡 * e^𝑝\n",
    "        cost = self.alpha * np.exp(power/10)\n",
    "\n",
    "        # Update battery level\n",
    "        self.battery_level = min(self.battery_level + power / 4, self.battery_capacity) # each time 15 min, power * 15min = power * 1hour / 4\n",
    "\n",
    "        # Reduce the steps left by 1\n",
    "        self.steps_left -= 1\n",
    "\n",
    "        # If steps are finished, calculate if the battery meets the demand\n",
    "        if self.steps_left == 0:\n",
    "            demand = np.random.normal(self.mu, self.sigma)\n",
    "            if self.battery_level >= demand:\n",
    "                reward = -cost  # Minimize cost, no penalty for meeting demand\n",
    "            else:\n",
    "                reward = -cost - 1000  # High penalty for not meeting demand\n",
    "            terminated = True\n",
    "        else:\n",
    "            reward = -cost  # Incur cost for charging, continue episode\n",
    "            terminated = False\n",
    "\n",
    "        # Always set truncated to False in this environment\n",
    "        truncated = False\n",
    "\n",
    "        # State is the current battery level\n",
    "        self.state = np.array([self.battery_level], dtype=np.float32)\n",
    "\n",
    "        # Info dictionary\n",
    "        info = {\n",
    "            \"battery_level\": self.battery_level,\n",
    "            \"cost\": cost\n",
    "        }\n",
    "\n",
    "        return self.state, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        # Reset battery level\n",
    "        self.battery_level = float(random.randint(20, 30))\n",
    "        # Reset steps left\n",
    "        self.steps_left = 8\n",
    "        # Reset state\n",
    "        self.state = np.array([self.battery_level], dtype=np.float32)\n",
    "        return self.state, {}\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        # For visualization, if needed\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = TaxiChargingEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Validate and test the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the environment follow Gym interface that SB3 support\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0.0, 100.0, (1,), float32)\n",
      "Discrete(4)\n",
      "3\n",
      "Step 1\n",
      "obs= [21.75] reward= -2.0137527074704766 done= False info= {'battery_level': 21.75, 'cost': 2.0137527074704766}\n",
      "Step 2\n",
      "obs= [23.5] reward= -2.0137527074704766 done= False info= {'battery_level': 23.5, 'cost': 2.0137527074704766}\n",
      "Step 3\n",
      "obs= [29.] reward= -9.025013499434122 done= False info= {'battery_level': 29.0, 'cost': 9.025013499434122}\n",
      "Step 4\n",
      "obs= [34.5] reward= -9.025013499434122 done= False info= {'battery_level': 34.5, 'cost': 9.025013499434122}\n",
      "Step 5\n",
      "obs= [34.5] reward= -1.0 done= False info= {'battery_level': 34.5, 'cost': 1.0}\n",
      "Step 6\n",
      "obs= [34.5] reward= -1.0 done= False info= {'battery_level': 34.5, 'cost': 1.0}\n",
      "Step 7\n",
      "obs= [34.5] reward= -1.0 done= False info= {'battery_level': 34.5, 'cost': 1.0}\n",
      "Step 8\n",
      "obs= [34.5] reward= -1.0 done= True info= {'battery_level': 34.5, 'cost': 1.0}\n",
      "Goal reached! reward= -1.0\n"
     ]
    }
   ],
   "source": [
    "obs, _ = env.reset()\n",
    "env.render()\n",
    "\n",
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "print(env.action_space.sample())\n",
    "\n",
    "# Random agent\n",
    "n_steps = 8\n",
    "for step in range(n_steps):\n",
    "    action = env.action_space.sample()  # Random action\n",
    "    print(f\"Step {step + 1}\")\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    print(\"obs=\", obs, \"reward=\", reward, \"done=\", done, \"info=\", info)\n",
    "    env.render()\n",
    "    if done:\n",
    "        print(\"Goal reached!\", \"reward=\", reward)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Stable-Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "vec_env = make_vec_env(lambda: env, n_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 8        |\n",
      "|    ep_rew_mean     | -81.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 6552     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -48.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4450        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017819522 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -6.65e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.31e+04    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    value_loss           | 1.61e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -124        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4094        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021206887 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -1.3e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.77e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | 0.00446     |\n",
      "|    value_loss           | 2.36e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -66.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3943         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035888772 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | -3.81e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.75e+04     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    value_loss           | 5.91e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -77.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3864        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012018211 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -1.79e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.23e+04    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    value_loss           | 3.58e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -70.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3802        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008473927 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -9.54e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.94e+04    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | 0.000107    |\n",
      "|    value_loss           | 2.8e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -43.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3762        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009588841 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.77e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.001      |\n",
      "|    value_loss           | 1.29e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -43.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3734         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017418463 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.000767     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+04     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00114     |\n",
      "|    value_loss           | 1.04e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -49.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3710        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017334912 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.00341     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 79          |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    value_loss           | 2.8e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -58.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3679        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000501674 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.00355     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.17e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.000124   |\n",
      "|    value_loss           | 1.79e+04    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -49.4         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3668          |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 6             |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016561351 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.35         |\n",
      "|    explained_variance   | 0.00393       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 77.6          |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.000299     |\n",
      "|    value_loss           | 1.03e+04      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -88         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3659        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002336033 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.0098      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64          |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    value_loss           | 1.03e+04    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -27.4         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3651          |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 7             |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081181596 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.33         |\n",
      "|    explained_variance   | 0.00991       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 100           |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.000701     |\n",
      "|    value_loss           | 2.29e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -78.2         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3637          |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 7             |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066676456 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.34         |\n",
      "|    explained_variance   | 0.0105        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.69e+04      |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.00132      |\n",
      "|    value_loss           | 1.27e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -40.1         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3629          |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094749907 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.33         |\n",
      "|    explained_variance   | 0.00999       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.64e+04      |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.00141      |\n",
      "|    value_loss           | 2.28e+04      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -36         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3618        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025254779 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.0194      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 5.2e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -66.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3605         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012746224 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.0154       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.58e+04     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    value_loss           | 2.27e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -46.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3594         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003657975 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.0148       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 92.2         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.000381    |\n",
      "|    value_loss           | 2.03e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -55.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3587         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045267018 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.0216       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.05e+04     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00557     |\n",
      "|    value_loss           | 1.02e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -45.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3583         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007686851 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.0148       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.28e+03     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000781    |\n",
      "|    value_loss           | 2.27e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -44.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3581        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007281622 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.0216      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.1        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    value_loss           | 1.02e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -74.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3579         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010812064 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.0123       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.79e+03     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000836    |\n",
      "|    value_loss           | 2.02e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -76.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3576        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005040848 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.0126      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.14e+04    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    value_loss           | 3.74e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -57.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3575         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018163901 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0.0163       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.05e+04     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    value_loss           | 2.5e+04      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8          |\n",
      "|    ep_rew_mean          | -34.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3569       |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00828987 |\n",
      "|    clip_fraction        | 0.0526     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | 0.0195     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.61e+03   |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.00506   |\n",
      "|    value_loss           | 1.02e+04   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -45.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3568         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039277603 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0.0131       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.94e+03     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    value_loss           | 1.52e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -46.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3568         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023067463 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.013        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.98e+03     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    value_loss           | 1.52e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -25.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3567        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009463512 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.0284      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.71e+03    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    value_loss           | 1.01e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -74.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3563         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027301959 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.013        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01e+04     |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    value_loss           | 2.02e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8          |\n",
      "|    ep_rew_mean          | -44.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3559       |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00924835 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0.0196     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.36e+03   |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0018    |\n",
      "|    value_loss           | 1.52e+04   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -43.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3555         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050680386 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.975       |\n",
      "|    explained_variance   | 0.026        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.51e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -44.5         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3543          |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021340238 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.953        |\n",
      "|    explained_variance   | 0.021         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.71e+03      |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | 9.49e-05      |\n",
      "|    value_loss           | 1.77e+04      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -43.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3530        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014880596 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.902      |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67          |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    value_loss           | 7.72e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -22.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3528         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024534273 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.819       |\n",
      "|    explained_variance   | 0.00795      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.98e+03     |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    value_loss           | 1.53e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -50.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3526        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024518853 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.714      |\n",
      "|    explained_variance   | 0.0231      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    value_loss           | 5.26e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -70.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3522        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003660677 |\n",
      "|    clip_fraction        | 0.0084      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.42e+03    |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    value_loss           | 2.51e+04    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -60           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3518          |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 21            |\n",
      "|    total_timesteps      | 75776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00052585534 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.686        |\n",
      "|    explained_variance   | 0.0244        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.08e+04      |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | -0.00112      |\n",
      "|    value_loss           | 2.25e+04      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -69.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3513        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000377258 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | 0.00634     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.56e+03    |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.000498   |\n",
      "|    value_loss           | 1.79e+04    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -30.6         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3509          |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 22            |\n",
      "|    total_timesteps      | 79872         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017754367 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.663        |\n",
      "|    explained_variance   | 0.0171        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.19e+03      |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | -0.000439     |\n",
      "|    value_loss           | 1.77e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -50.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3509         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011396988 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.681       |\n",
      "|    explained_variance   | 0.012        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.33e+03     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.000591    |\n",
      "|    value_loss           | 1.78e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -51.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3508         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042836033 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.718       |\n",
      "|    explained_variance   | 0.0144       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 426          |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    value_loss           | 2.27e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -51.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3507         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032059178 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.778       |\n",
      "|    explained_variance   | 0.0147       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.77e+03     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    value_loss           | 2.27e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -43.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3505         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012651056 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.79        |\n",
      "|    explained_variance   | 0.0223       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.73e+03     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.000232    |\n",
      "|    value_loss           | 1.28e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -21.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3504        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007083168 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.0176      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.99e+03    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    value_loss           | 1.03e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -39.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3502        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048097517 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.656      |\n",
      "|    explained_variance   | 0.0307      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.16        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    value_loss           | 2.62e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -29.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3501         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036150995 |\n",
      "|    clip_fraction        | 0.0516       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.624       |\n",
      "|    explained_variance   | 0.00704      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.21e+03     |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | 0.00113      |\n",
      "|    value_loss           | 1.54e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -20.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3501         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001495838 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.627       |\n",
      "|    explained_variance   | 0.0139       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.9e+04      |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.000328    |\n",
      "|    value_loss           | 3.24e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -40.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3499         |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017918542 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.616       |\n",
      "|    explained_variance   | 0.0155       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.1         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    value_loss           | 7.79e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -39.7         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3498          |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 28            |\n",
      "|    total_timesteps      | 100352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.0108224e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.592        |\n",
      "|    explained_variance   | 0.0156        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 318           |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -0.000188     |\n",
      "|    value_loss           | 2.5e+04       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x3136edd30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "\n",
    "# Train the agent using PPO\n",
    "model = PPO(\"MlpPolicy\", vec_env, verbose=1)\n",
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, save the model\n",
    "model.save(\"ppo_taxi_charging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"ppo_taxi_charging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward: [-18.151468]\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "state = vec_env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "while not done:\n",
    "    action, _states = model.predict(state)\n",
    "    state, reward, done, info = vec_env.step(action)\n",
    "    total_reward += reward\n",
    "\n",
    "print(f\"Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with random action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  code below show each rewards if we choose random action for 50 episode, as well as the average of 50 episodes\n",
    "2.  if the test episode include the case that energy demand is higher than the energy we have, reward will be extremely low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 - Total Reward: -25.190613399968147\n",
      "Episode 2 - Total Reward: -39.199193139462196\n",
      "Episode 3 - Total Reward: -30.14648508812435\n",
      "Episode 4 - Total Reward: -31.160237795594824\n",
      "Episode 5 - Total Reward: -24.162918848064425\n",
      "Episode 6 - Total Reward: -32.187932347498545\n",
      "Episode 7 - Total Reward: -40.21294584693267\n",
      "Episode 8 - Total Reward: -28.231871522379578\n",
      "Episode 9 - Total Reward: -27.344952508538526\n",
      "Episode 10 - Total Reward: -21.107718881219753\n",
      "Episode 11 - Total Reward: -41.22669855440314\n",
      "Episode 12 - Total Reward: -42.25439310630687\n",
      "Episode 13 - Total Reward: -38.171498587558474\n",
      "Episode 14 - Total Reward: -22.248305282319652\n",
      "Episode 15 - Total Reward: -34.22937960687274\n",
      "Episode 16 - Total Reward: -27.2181188149091\n",
      "Episode 17 - Total Reward: -25.176671555534902\n",
      "Episode 18 - Total Reward: -20.08002432931603\n",
      "Episode 19 - Total Reward: -21.10771888121975\n",
      "Episode 20 - Total Reward: -30.273318781753773\n",
      "Episode 21 - Total Reward: -1018.1793526080046\n",
      "Episode 22 - Total Reward: -24.162918848064425\n",
      "Episode 23 - Total Reward: -16.1379053486303\n",
      "Episode 24 - Total Reward: -39.18525129502894\n",
      "Episode 25 - Total Reward: -36.256885021813694\n",
      "Episode 26 - Total Reward: -37.28457957371742\n",
      "Episode 27 - Total Reward: -33.08879320577284\n",
      "Episode 28 - Total Reward: -17.165599900534023\n",
      "Episode 29 - Total Reward: -32.187932347498545\n",
      "Episode 30 - Total Reward: -37.157745880087994\n",
      "Episode 31 - Total Reward: -30.14648508812435\n",
      "Episode 32 - Total Reward: -43.141312120147916\n",
      "Episode 33 - Total Reward: -35.24313231434322\n",
      "Episode 34 - Total Reward: -24.162918848064425\n",
      "Episode 35 - Total Reward: -23.135224296160704\n",
      "Episode 36 - Total Reward: -1020.0939661737493\n",
      "Episode 37 - Total Reward: -1016.1239635041971\n",
      "Episode 38 - Total Reward: -23.26205798979013\n",
      "Episode 39 - Total Reward: -24.28975254169385\n",
      "Episode 40 - Total Reward: -36.14399317261752\n",
      "Episode 41 - Total Reward: -33.20168505496902\n",
      "Episode 42 - Total Reward: -28.105037828750152\n",
      "Episode 43 - Total Reward: -22.248305282319652\n",
      "Episode 44 - Total Reward: -52.19402017148577\n",
      "Episode 45 - Total Reward: -35.24313231434322\n",
      "Episode 46 - Total Reward: -40.21294584693267\n",
      "Episode 47 - Total Reward: -38.17149858755847\n",
      "Episode 48 - Total Reward: -47.22420663889631\n",
      "Episode 49 - Total Reward: -32.187932347498545\n",
      "Episode 50 - Total Reward: -28.105037828750152\n",
      "Average Reward over 50 episodes: -90.48749137715045\n"
     ]
    }
   ],
   "source": [
    "def test_environment(env, num_episodes=50):\n",
    "    rewards = []\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state, _ = env.reset()  # Reset the environment to start a new episode\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        \n",
    "        while not done:\n",
    "            action = env.action_space.sample()  # Take a random action\n",
    "            next_state, reward, done, truncated, info = env.step(action)\n",
    "            total_reward += reward  # Accumulate the reward\n",
    "            state = next_state  # Move to the next state\n",
    "        \n",
    "        rewards.append(total_reward)  # Store the total reward for this episode\n",
    "        print(f\"Episode {episode + 1} - Total Reward: {total_reward}\")\n",
    "\n",
    "    average_reward = np.mean(rewards)  # Calculate the average reward\n",
    "    print(f\"Average Reward over {num_episodes} episodes: {average_reward}\")\n",
    "\n",
    "# Test the environment with random actions for 20 episodes\n",
    "test_environment(env, num_episodes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
