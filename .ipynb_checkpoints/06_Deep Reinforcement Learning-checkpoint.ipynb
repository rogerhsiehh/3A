{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install gym\n",
    "# !pip install keras\n",
    "# !pip install keras-rl2\n",
    "# !pip install stable-baselines3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create environment follows Gym that SB3 supports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.youtube.com/watch?v=cO5g5qLrLSo&ab_channel=NicholasRenotte\n",
    "* https://www.youtube.com/watch?v=bD6V3rcr_54&list=PLgNJO2hghbmjlE6cuKMws2ejC54BTAaWV&index=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "class TaxiChargingEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(TaxiChargingEnv, self).__init__()\n",
    "        # Actions we take: 0 kW, 7 kW, 14 kW, 22 kW\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        # State represents battery charge level (kWh)\n",
    "        self.observation_space = spaces.Box(low=np.array([0]), high=np.array([100]), dtype=np.float32)\n",
    "        # Initialize state\n",
    "        self.state = 0.0\n",
    "        # Battery capacity\n",
    "        self.battery_capacity = 100.0  # kWh\n",
    "        # Initial battery level\n",
    "        self.battery_level = float(random.randint(20, 30))\n",
    "        # Charging period (2 hours, every 15 minutes = 8 steps)\n",
    "        self.steps_left = 8\n",
    "        # Energy demand parameters\n",
    "        self.mu = 30.0  # kWh\n",
    "        self.sigma = 5.0  # kWh\n",
    "        # Time coefficient for cost function\n",
    "        self.alpha = 1\n",
    "\n",
    "    def step(self, action):\n",
    "        charging_rates = [0, 7, 14, 22]  # kW for each action\n",
    "        power = charging_rates[action]\n",
    "\n",
    "        # Calculate cost: charging cost (t,p) = 𝛼𝑡 * e^𝑝\n",
    "        cost = self.alpha * np.exp(power/10)\n",
    "\n",
    "        # Update battery level\n",
    "        self.battery_level = min(self.battery_level + power / 4, self.battery_capacity) # each time 15 min, power * 15min = power * 1hour / 4\n",
    "\n",
    "        # Reduce the steps left by 1\n",
    "        self.steps_left -= 1\n",
    "\n",
    "        # If steps are finished, calculate if the battery meets the demand\n",
    "        if self.steps_left == 0:\n",
    "            demand = np.random.normal(self.mu, self.sigma)\n",
    "            if self.battery_level >= demand:\n",
    "                reward = -cost  # Minimize cost, no penalty for meeting demand\n",
    "            else:\n",
    "                reward = -cost - 1000  # High penalty for not meeting demand\n",
    "            terminated = True\n",
    "        else:\n",
    "            reward = -cost  # Incur cost for charging, continue episode\n",
    "            terminated = False\n",
    "\n",
    "        # Always set truncated to False in this environment\n",
    "        truncated = False\n",
    "\n",
    "        # State is the current battery level\n",
    "        self.state = np.array([self.battery_level], dtype=np.float32)\n",
    "\n",
    "        # Info dictionary\n",
    "        info = {\n",
    "            \"battery_level\": self.battery_level,\n",
    "            \"cost\": cost\n",
    "        }\n",
    "\n",
    "        return self.state, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        # Reset battery level\n",
    "        self.battery_level = float(random.randint(20, 30))\n",
    "        # Reset steps left\n",
    "        self.steps_left = 8\n",
    "        # Reset state\n",
    "        self.state = np.array([self.battery_level], dtype=np.float32)\n",
    "        return self.state, {}\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        # For visualization, if needed\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = TaxiChargingEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Validate and test the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the environment follow Gym interface that SB3 support\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0.0, 100.0, (1,), float32)\n",
      "Discrete(4)\n",
      "3\n",
      "Step 1\n",
      "obs= [31.5] reward= -4.0551999668446745 done= False info= {'battery_level': 31.5, 'cost': 4.0551999668446745}\n",
      "Step 2\n",
      "obs= [35.] reward= -4.0551999668446745 done= False info= {'battery_level': 35.0, 'cost': 4.0551999668446745}\n",
      "Step 3\n",
      "obs= [38.5] reward= -4.0551999668446745 done= False info= {'battery_level': 38.5, 'cost': 4.0551999668446745}\n",
      "Step 4\n",
      "obs= [44.] reward= -9.025013499434122 done= False info= {'battery_level': 44.0, 'cost': 9.025013499434122}\n",
      "Step 5\n",
      "obs= [49.5] reward= -9.025013499434122 done= False info= {'battery_level': 49.5, 'cost': 9.025013499434122}\n",
      "Step 6\n",
      "obs= [49.5] reward= -1.0 done= False info= {'battery_level': 49.5, 'cost': 1.0}\n",
      "Step 7\n",
      "obs= [51.25] reward= -2.0137527074704766 done= False info= {'battery_level': 51.25, 'cost': 2.0137527074704766}\n",
      "Step 8\n",
      "obs= [56.75] reward= -9.025013499434122 done= True info= {'battery_level': 56.75, 'cost': 9.025013499434122}\n",
      "Goal reached! reward= -9.025013499434122\n"
     ]
    }
   ],
   "source": [
    "obs, _ = env.reset()\n",
    "env.render()\n",
    "\n",
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "print(env.action_space.sample())\n",
    "\n",
    "# Random agent\n",
    "n_steps = 8\n",
    "for step in range(n_steps):\n",
    "    action = env.action_space.sample()  # Random action\n",
    "    print(f\"Step {step + 1}\")\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    print(\"obs=\", obs, \"reward=\", reward, \"done=\", done, \"info=\", info)\n",
    "    env.render()\n",
    "    if done:\n",
    "        print(\"Goal reached!\", \"reward=\", reward)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Stable-Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "vec_env = make_vec_env(lambda: env, n_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 8        |\n",
      "|    ep_rew_mean     | -53.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 6302     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -68.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4138        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018566348 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 9.25e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.03e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    value_loss           | 1.07e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -173        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3953        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030264692 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -9.78e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+04    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | 0.000547    |\n",
      "|    value_loss           | 1.83e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -65.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3777         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040717046 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | -3.58e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.9e+04      |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    value_loss           | 6.94e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -113        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3716        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011973469 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -1.79e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.44e+04    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | 0.00206     |\n",
      "|    value_loss           | 3.07e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -73.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3688        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007308821 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -1.43e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83e+04    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    value_loss           | 5.81e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -110        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3651        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035416167 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | -7.15e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.06e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.000481   |\n",
      "|    value_loss           | 3.53e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -90.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3642         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026866053 |\n",
      "|    clip_fraction        | 0.213        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | -3.58e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.96e+04     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | 0.00648      |\n",
      "|    value_loss           | 5.96e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -63         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3621        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009183422 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.38e+04    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 4.94e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -35         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3608        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008806482 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | -5.96e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.34e+04    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    value_loss           | 3.25e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -48         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3598        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009280123 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 525         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    value_loss           | 2.52e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -41.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3515        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009454677 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.36e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | 0.00445     |\n",
      "|    value_loss           | 1.56e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8          |\n",
      "|    ep_rew_mean          | -28.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3515       |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00667633 |\n",
      "|    clip_fraction        | 0.0561     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.23      |\n",
      "|    explained_variance   | 0.000256   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.31e+04   |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.00778   |\n",
      "|    value_loss           | 5.56e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -37.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3493        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009284978 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.000226    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    value_loss           | 7.89e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -44.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3493        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017232891 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.00119     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 5.29e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -44         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3490        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002504046 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.00474     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.31e+04    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.000951   |\n",
      "|    value_loss           | 1.79e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -53.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3488         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036376545 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.00977      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    value_loss           | 7.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -44.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3486         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038502733 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.0118       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+04     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    value_loss           | 1.78e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -76.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3486         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029302547 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.014        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 106          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00096     |\n",
      "|    value_loss           | 1.53e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -37.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3483        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002324813 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.0143      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.38e+04    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    value_loss           | 3.27e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -37.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3482         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057300017 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0.0157       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.2e+04      |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    value_loss           | 1.27e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -75          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3481         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041982005 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.0243       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.2e+04      |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    value_loss           | 7.7e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -26.4         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3480          |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 13            |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017775912 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.0141        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.11e+03      |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.000466     |\n",
      "|    value_loss           | 1.53e+04      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -61.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3473        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025867011 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.034       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 2.63e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -71.9         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3475          |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022723919 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0.0171        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.12e+04      |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -0.000582     |\n",
      "|    value_loss           | 1.27e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -53.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3476         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012579376 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.0211       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36e+04     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    value_loss           | 3.24e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -53.1         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3476          |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 55296         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028287485 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0.0218        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.04e+03      |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | -0.00105      |\n",
      "|    value_loss           | 1.02e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -44.2         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3476          |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 16            |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045890507 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.997        |\n",
      "|    explained_variance   | 0.0247        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.03e+04      |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.000596     |\n",
      "|    value_loss           | 1.76e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -25          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3475         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011875601 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.992       |\n",
      "|    explained_variance   | 0.0144       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 212          |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000653    |\n",
      "|    value_loss           | 1.78e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -34.4         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3475          |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016224146 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.989        |\n",
      "|    explained_variance   | 0.0226        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 71.5          |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | 5.76e-05      |\n",
      "|    value_loss           | 1.27e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -33.6         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3474          |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 63488         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095017557 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.987        |\n",
      "|    explained_variance   | 0.0232        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.93e+03      |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | -0.000423     |\n",
      "|    value_loss           | 1.27e+04      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -22.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3474        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016490042 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.935      |\n",
      "|    explained_variance   | 0.0269      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.27e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    value_loss           | 5.19e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -31.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3470        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014494413 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.862      |\n",
      "|    explained_variance   | 0.0134      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.84e+03    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    value_loss           | 7.8e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -30.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3470        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007751106 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.732      |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.8         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    value_loss           | 5.23e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -59.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3469         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060995235 |\n",
      "|    clip_fraction        | 0.0514       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.63        |\n",
      "|    explained_variance   | 0.0123       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.9e+03      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    value_loss           | 1.03e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -29.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3469         |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001819747 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.621       |\n",
      "|    explained_variance   | 0.0157       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.75e+03     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.000806    |\n",
      "|    value_loss           | 3.25e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -39.2         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3465          |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 21            |\n",
      "|    total_timesteps      | 75776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019586357 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.611        |\n",
      "|    explained_variance   | 0.0165        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 94            |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | 1.6e-05       |\n",
      "|    value_loss           | 1.28e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -59.3         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3466          |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 22            |\n",
      "|    total_timesteps      | 77824         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014623936 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.608        |\n",
      "|    explained_variance   | 0.0095        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 449           |\n",
      "|    n_updates            | 370           |\n",
      "|    policy_gradient_loss | -0.000163     |\n",
      "|    value_loss           | 2.52e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -49.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3465         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.995406e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.614       |\n",
      "|    explained_variance   | 0.012        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+04     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.000225    |\n",
      "|    value_loss           | 1.78e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8             |\n",
      "|    ep_rew_mean          | -48.7         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 3465          |\n",
      "|    iterations           | 40            |\n",
      "|    time_elapsed         | 23            |\n",
      "|    total_timesteps      | 81920         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048049295 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.605        |\n",
      "|    explained_variance   | 0.0233        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.05e+04      |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -0.00122      |\n",
      "|    value_loss           | 2.01e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -49.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3464         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020827393 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.628       |\n",
      "|    explained_variance   | 0.019        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.23e+04     |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    value_loss           | 1.77e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -30.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3463         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008829007 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.666       |\n",
      "|    explained_variance   | 0.0151       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+04     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | 7.98e-05     |\n",
      "|    value_loss           | 2.27e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -41.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3462         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058631278 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.72        |\n",
      "|    explained_variance   | 0.0227       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.69e+03     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    value_loss           | 1.27e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -51.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3462        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007078453 |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.772      |\n",
      "|    explained_variance   | 0.0213      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.13e+03    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    value_loss           | 1.77e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -33.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3462        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007749821 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | 0.0296      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    value_loss           | 1.51e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -33.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3461         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024514901 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.838       |\n",
      "|    explained_variance   | 0.0289       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.08e+03     |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | 0.000441     |\n",
      "|    value_loss           | 7.7e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8           |\n",
      "|    ep_rew_mean          | -32.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3458        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015772182 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.785      |\n",
      "|    explained_variance   | 0.0109      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    value_loss           | 7.77e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8            |\n",
      "|    ep_rew_mean          | -42.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3458         |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084327925 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.786       |\n",
      "|    explained_variance   | 0.00925      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.27e+03     |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.000506    |\n",
      "|    value_loss           | 1.28e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8          |\n",
      "|    ep_rew_mean          | -21.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3458       |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01438331 |\n",
      "|    clip_fraction        | 0.0523     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.761     |\n",
      "|    explained_variance   | 0.0129     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 84.8       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00493   |\n",
      "|    value_loss           | 1.03e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x17e1ee4c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "\n",
    "# Train the agent using PPO\n",
    "model = PPO(\"MlpPolicy\", vec_env, verbose=1)\n",
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, save the model\n",
    "model.save(\"ppo_taxi_charging\")\n",
    "\n",
    "# To load and use the model later\n",
    "model = PPO.load(\"ppo_taxi_charging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward: [-18.151468]\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "state = vec_env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "while not done:\n",
    "    action, _states = model.predict(state)\n",
    "    state, reward, done, info = vec_env.step(action)\n",
    "    total_reward += reward\n",
    "\n",
    "print(f\"Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code below show choosing random action for 200 episodes, the average reward is  -81.30168659640917"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 - Total Reward: -25.176671555534902\n",
      "Episode 2 - Total Reward: -27.2181188149091\n",
      "Episode 3 - Total Reward: -37.28457957371742\n",
      "Episode 4 - Total Reward: -13.068763537352384\n",
      "Episode 5 - Total Reward: -37.157745880087994\n",
      "Episode 6 - Total Reward: -37.157745880087994\n",
      "Episode 7 - Total Reward: -25.176671555534902\n",
      "Episode 8 - Total Reward: -36.27082686624694\n",
      "Episode 9 - Total Reward: -32.187932347498545\n",
      "Episode 10 - Total Reward: -60.21903367091989\n",
      "Episode 11 - Total Reward: -43.268145813777345\n",
      "Episode 12 - Total Reward: -25.162729711101655\n",
      "Episode 13 - Total Reward: -37.157745880087994\n",
      "Episode 14 - Total Reward: -19.193105315474977\n",
      "Episode 15 - Total Reward: -36.2568850218137\n",
      "Episode 16 - Total Reward: -19.193105315474977\n",
      "Episode 17 - Total Reward: -31.174179640028072\n",
      "Episode 18 - Total Reward: -39.32602683309162\n",
      "Episode 19 - Total Reward: -21.234552574849175\n",
      "Episode 20 - Total Reward: -1023.1491661405939\n",
      "Average Reward over 20 episodes: -81.30168659640917\n"
     ]
    }
   ],
   "source": [
    "# def test_environment(env, num_episodes=20):\n",
    "#     rewards = []\n",
    "    \n",
    "#     for episode in range(num_episodes):\n",
    "#         state, _ = env.reset()  # Reset the environment to start a new episode\n",
    "#         done = False\n",
    "#         total_reward = 0\n",
    "        \n",
    "#         while not done:\n",
    "#             action = env.action_space.sample()  # Take a random action\n",
    "#             next_state, reward, done, truncated, info = env.step(action)\n",
    "#             total_reward += reward  # Accumulate the reward\n",
    "#             state = next_state  # Move to the next state\n",
    "        \n",
    "#         rewards.append(total_reward)  # Store the total reward for this episode\n",
    "#         print(f\"Episode {episode + 1} - Total Reward: {total_reward}\")\n",
    "\n",
    "#     average_reward = np.mean(rewards)  # Calculate the average reward\n",
    "#     print(f\"Average Reward over {num_episodes} episodes: {average_reward}\")\n",
    "\n",
    "# # Test the environment with random actions for 20 episodes\n",
    "# test_environment(env, num_episodes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
